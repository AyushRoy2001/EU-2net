{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nfrom glob import glob\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose, Dense, Reshape, Flatten, Softmax, Lambda, SeparableConv2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import MeanIoU\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import kl_div","metadata":{"executionInfo":{"elapsed":3544,"status":"ok","timestamp":1674714140032,"user":{"displayName":"Arpita Roy","userId":"08870327934458985768"},"user_tz":-330},"id":"b041422f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{"id":"835ef538"}},{"cell_type":"markdown","source":"#### Custom Dataloader","metadata":{}},{"cell_type":"code","source":"def load_image(path, size):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (size,size))\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)   # shape: (size,size,3) -> (size,size,1)\n    image = image/255.   # normalize\n    return image\n\ndef load_data(root_path, size):\n    images = []\n    masks = []\n    \n    x = 0   # additional variable to identify images consisting of 2 or more masks\n    \n    for path in sorted(glob(root_path)):\n        img = load_image(path, size)   # read mask or image\n            \n        if 'mask' in path:\n            if x:   # this image has masks more than one\n                masks[-1] += img   # add the mask to the last mask\n                    \n                # When 2 masks are added, the range can increase by 0-2. So we will reduce it again to the range 0-1.\n                masks[-1] = np.array(masks[-1]>0.5, dtype='float64')\n            else:\n                masks.append(img)\n                x = 1   # if the image has a mask again, the above code will run next time\n        else:\n            images.append(img)\n            x = 0   # for moving to the next image\n    return np.array(images), np.array(masks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size = 512 # image size: 512x512\nroot_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/*/*'\nX, y = load_data(root_path, size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop normal class because normal class has not mask\nX = X[:647]\ny = y[:647]\n\nprint(f\"X shape: {X.shape}     |  y shape: {y.shape}\")\n\n# prepare data to modeling\nX = np.expand_dims(X, -1)\ny = np.expand_dims(y, -1)\n\nprint(f\"\\nX shape: {X.shape}  |  y shape: {y.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n\nprint('X_train shape:',X_train.shape)\nprint('y_train shape:',y_train.shape)\nprint('X_val shape:',X_val.shape)\nprint('y_val shape:',y_val.shape)\nprint('X_test shape:',X_test.shape)\nprint('y_test shape:',y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualization of training images","metadata":{}},{"cell_type":"code","source":"image = X_train[31]\nmask = y_train[31]\n\nfig, axes = plt.subplots(1, 2, figsize=(5, 2))\naxes[0].imshow(image, cmap='gray')\naxes[0].axis('off')\naxes[0].set_title('Image')\n\naxes[1].imshow(mask*255, cmap='gray', vmin=0, vmax=1)\naxes[1].axis('off')\naxes[1].set_title('Mask')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualization of validation images","metadata":{}},{"cell_type":"code","source":"image = X_test[4]\nmask = y_test[4]\n\nfig, axes = plt.subplots(1, 2, figsize=(5, 2))\naxes[0].imshow(image, cmap='gray')\naxes[0].axis('off')\naxes[0].set_title('Image')\n\naxes[1].imshow(mask*255, cmap='gray', vmin=0, vmax=1)\naxes[1].axis('off')\naxes[1].set_title('Mask')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualization of testing images","metadata":{}},{"cell_type":"code","source":"image = X_test[5]\nmask = y_test[5]\n\nfig, axes = plt.subplots(1, 2, figsize=(5, 2))\naxes[0].imshow(image, cmap='gray')\naxes[0].axis('off')\naxes[0].set_title('Image')\n\naxes[1].imshow(mask*255, cmap='gray', vmin=0, vmax=1)\naxes[1].axis('off')\naxes[1].set_title('Mask')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom metrics and losses","metadata":{}},{"cell_type":"markdown","source":"#### Metrics","metadata":{}},{"cell_type":"code","source":"def dice_score(y_true, y_pred):\n    smooth = K.epsilon()\n    y_true_flat = K.flatten(y_true)\n    y_pred_flat = K.flatten(y_pred)\n    intersection = K.sum(y_true_flat * y_pred_flat)\n    score = (2. * intersection + smooth) / (K.sum(y_true_flat) + K.sum(y_pred_flat) + smooth)\n    return score\n\ndef iou(y_true, y_pred):\n    smooth = K.epsilon()\n    y_true_flat = K.flatten(y_true)\n    y_pred_flat = K.flatten(y_pred)\n    intersection = K.sum(y_true_flat * y_pred_flat)\n    union = K.sum(y_true_flat) + K.sum(y_pred_flat) - intersection + smooth\n    iou = (intersection + smooth) / union\n    return iou\n\ndef recall(y_true, y_pred):\n    smooth = K.epsilon()\n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n    y_true_flat = K.flatten(y_true)\n    y_pred_flat = K.flatten(y_pred_pos)\n    tp = K.sum(y_true_flat * y_pred_flat)\n    fn = K.sum(y_true_flat * (1 - y_pred_flat))\n    recall = (tp + smooth) / (tp + fn + smooth)\n    return recall\n\ndef precision(y_true, y_pred):\n    smooth = K.epsilon()\n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n    y_true_flat = K.flatten(y_true)\n    y_pred_flat = K.flatten(y_pred_pos)\n    tp = K.sum(y_true_flat * y_pred_flat)\n    fp = K.sum((1 - y_true_flat) * y_pred_flat)\n    precision = (tp + smooth) / (tp + fp + smooth)\n    return precision","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loss","metadata":{}},{"cell_type":"code","source":"def dice_loss(y_true, y_pred):\n    loss = 1 - dice_score(y_true, y_pred)\n    return loss\n\ndef iou_loss(y_true, y_pred):\n    loss = 1 - iou(y_true, y_pred)\n    return loss\n    \ndef focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n    epsilon = tf.keras.backend.epsilon()\n    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n    y_true = tf.cast(y_true, tf.float32)\n    pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n    focal_weight = alpha * tf.pow(1 - pt, gamma)\n    loss = tf.reduce_mean(-focal_weight * tf.math.log(pt))\n    return loss\n\ndef bce_loss(y_true, y_pred):\n    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n    return loss\n\ndef combined_loss(y_true, y_pred):\n    loss = dice_loss(y_true, y_pred) + bce_loss(y_true, y_pred)\n    return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom UNet architecture","metadata":{"id":"a8a99350"}},{"cell_type":"markdown","source":"#### Wavelet","metadata":{}},{"cell_type":"code","source":"def wavelet(feature_map):\n    B,H,W,C = feature_map.shape\n    wav = tf.image.sobel_edges(feature_map)\n    wav1 = wav[:,:,:,0]\n    wav2 = wav[:,:,:,1]\n    wav = tf.keras.layers.Concatenate()([wav1,wav2])\n    wav = tf.keras.layers.Conv2D(2*C, (3,3), (1,1),padding=\"same\")(wav) \n    wav = tf.keras.layers.Conv2D(C, (1,1), (1,1),padding=\"same\")(wav) \n    return wav ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### SE Block","metadata":{}},{"cell_type":"code","source":"def SE(x):\n    x = Conv2D(32, 3, padding=\"same\")(x)\n    x1 = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x1 = tf.keras.layers.Dense(8, activation='relu')(x1)\n    x1 = tf.keras.layers.Dense(32, activation='sigmoid')(x1)\n    x1 = tf.keras.layers.Reshape((1, 1, 32))(x1)\n    x = tf.keras.layers.Multiply()([x, x1])\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Similarity-aware Attention","metadata":{}},{"cell_type":"code","source":"def FSiAM(x):\n    x1 = tf.keras.layers.Permute((2, 1))(x)\n    x2 = tf.matmul(x1, x)\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    x2 = tf.keras.activations.sigmoid(x2)\n    x2 = tf.expand_dims(x2, axis=1)\n    x2 = tf.expand_dims(x2, axis=1)\n    return x2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ensemble Layer","metadata":{}},{"cell_type":"code","source":"class EnsembleLayer(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(EnsembleLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        super(EnsembleLayer, self).build(input_shape)\n        # trainable weight\n        self.weights_variable = tf.Variable(\n            initial_value=tf.ones((6,), dtype=tf.float32),\n            trainable=True,\n            name='weights'\n        )\n\n    def call(self, inputs):\n        y1, y2, y3, y4, y5, y6 = inputs\n        stacked_masks = tf.stack([y1, y2, y3, y4, y5, y6], axis=-1)\n        normalized_weights = tf.nn.softmax(self.weights_variable) # normalize weights between 0 and 1\n        final_mask = tf.reduce_sum(stacked_masks * tf.expand_dims(normalized_weights, axis=0), axis=-1)\n        #final_mask = tf.where(final_mask > 0.5, 1.0, 0.0)\n        return final_mask\n\n    def compute_output_shape(self, input_shape):\n        # The output shape is the same as the input shape of the masks (height, width, num_classes)\n        return input_shape[0][:-1] + (1,)\n\n    def get_config(self):\n        config = super().get_config()\n        return config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Custom U2NeT architecture","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Add\n\ndef conv_block(inputs, out_ch, rate=1):\n    x = SeparableConv2D(out_ch, 3, padding=\"same\", dilation_rate=1)(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\ndef RSU_L(inputs, out_ch, int_ch, num_layers, rate=2):\n    \"\"\" Initial Conv \"\"\"\n    x = conv_block(inputs, out_ch)\n    init_feats = x\n\n    \"\"\" Encoder \"\"\"\n    skip = []\n    x = conv_block(x, int_ch)\n    skip.append(x)\n\n    for i in range(num_layers-2):\n        x = MaxPool2D((2, 2))(x)\n        x = conv_block(x, int_ch)\n        skip.append(x)\n\n    \"\"\" Bridge \"\"\"\n    x = conv_block(x, int_ch, rate=rate)\n\n    \"\"\" Decoder \"\"\"\n    skip.reverse()\n\n    x = Concatenate()([x, skip[0]])\n    x = conv_block(x, int_ch)\n\n    for i in range(num_layers-3):\n        x = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)\n        x = Concatenate()([x, skip[i+1]])\n        x = conv_block(x, int_ch)\n\n    x = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)\n    x = Concatenate()([x, skip[-1]])\n    x = conv_block(x, out_ch)\n\n    \"\"\" Add \"\"\"\n    x = Add()([x, init_feats])\n    return x\n\ndef RSU_4F(inputs, out_ch, int_ch):\n    \"\"\" Initial Conv \"\"\"\n    x0 = conv_block(inputs, out_ch, rate=1)\n\n    \"\"\" Encoder \"\"\"\n    x1 = conv_block(x0, int_ch, rate=1)\n    x2 = conv_block(x1, int_ch, rate=2)\n    x3 = conv_block(x2, int_ch, rate=4)\n\n    \"\"\" Bridge \"\"\"\n    x4 = conv_block(x3, int_ch, rate=8)\n\n    \"\"\" Decoder \"\"\"\n    x = Concatenate()([x4, x3])\n    x = conv_block(x, int_ch, rate=4)\n\n    x = Concatenate()([x, x2])\n    x = conv_block(x, int_ch, rate=2)\n\n    x = Concatenate()([x, x1])\n    x = conv_block(x, out_ch, rate=1)\n\n    \"\"\" Addition \"\"\"\n    x = Add()([x, x0])\n    return x\n\ndef u2net(input_shape, out_ch, int_ch, num_classes=1):\n    \"\"\" Input Layer \"\"\"\n    inputs = Input(input_shape)\n    s0 = inputs\n\n    \"\"\" Encoder \"\"\"\n    s1 = RSU_L(s0, out_ch[0], int_ch[0], 7)\n    p1 = MaxPool2D((2, 2))(s1)\n\n    s2 = RSU_L(p1, out_ch[1], int_ch[1], 6)\n    p2 = MaxPool2D((2, 2))(s2)\n\n    s3 = RSU_L(p2, out_ch[2], int_ch[2], 5)\n    p3 = MaxPool2D((2, 2))(s3)\n\n    s4 = RSU_L(p3, out_ch[3], int_ch[3], 4)\n    p4 = MaxPool2D((2, 2))(s4)\n\n    s5 = RSU_4F(p4, out_ch[4], int_ch[4])\n    p5 = MaxPool2D((2, 2))(s5)\n\n    \"\"\" Bridge \"\"\"\n    b1 = RSU_4F(p5, out_ch[5], int_ch[5])\n    b2 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(b1)\n\n    \"\"\" Decoder \"\"\"\n    x = FSiAM(tf.keras.layers.Reshape((s5.shape[1]*s5.shape[2],s5.shape[3]))(s5))\n    x = tf.keras.layers.Multiply()([s5, x])\n    fft = wavelet(s5) \n    d1 = Concatenate(name=\"ONE\")([SE(b2), x, fft])\n    d1 = tf.keras.layers.SeparableConv2D(512,(3,3),(1, 1),padding=\"same\")(d1)\n    d1 = tf.keras.layers.SeparableConv2D(256,(1,1),(1, 1),padding=\"same\")(d1)\n    d1 = RSU_4F(d1, out_ch[6], int_ch[6])\n    u1 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d1)\n    \n    x = FSiAM(tf.keras.layers.Reshape((s4.shape[1]*s4.shape[2],s4.shape[3]))(s4))\n    x = tf.keras.layers.Multiply()([s4, x])\n    fft = wavelet(s4)\n    d2 = Concatenate(name=\"TWO\")([SE(u1), x, fft])\n    d2 = tf.keras.layers.SeparableConv2D(256,(3,3),(1, 1),padding=\"same\")(d2)\n    d2 = tf.keras.layers.SeparableConv2D(128,(1,1),(1, 1),padding=\"same\")(d2)\n    d2 = RSU_L(d2, out_ch[7], int_ch[7], 4)\n    u2 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d2)\n    \n    x = FSiAM(tf.keras.layers.Reshape((s3.shape[1]*s3.shape[2],s3.shape[3]))(s3))\n    x = tf.keras.layers.Multiply()([s3, x])\n    fft = wavelet(s3)\n    d3 = Concatenate(name=\"THREE\")([SE(u2), x, fft])\n    d3 = tf.keras.layers.SeparableConv2D(128,(3,3),(1, 1),padding=\"same\")(d3)\n    d3 = tf.keras.layers.SeparableConv2D(64,(1,1),(1, 1),padding=\"same\")(d3)\n    d3 = RSU_L(d3, out_ch[8], int_ch[8], 5)\n    u3 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d3)\n\n    x = FSiAM(tf.keras.layers.Reshape((s2.shape[1]*s2.shape[2],s2.shape[3]))(s2))\n    x = tf.keras.layers.Multiply()([s2, x])\n    fft = wavelet(s2)\n    d4 = Concatenate(name=\"FOUR\")([SE(u3), x, fft])\n    d4 = tf.keras.layers.SeparableConv2D(64,(3,3),(1, 1),padding=\"same\")(d4)\n    d4 = tf.keras.layers.SeparableConv2D(32,(1,1),(1, 1),padding=\"same\")(d4)\n    d4 = RSU_L(d4, out_ch[9], int_ch[9], 6)\n    u4 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d4)\n    \n    x = FSiAM(tf.keras.layers.Reshape((s1.shape[1]*s1.shape[2],s1.shape[3]))(s1))\n    x = tf.keras.layers.Multiply()([s1, x])\n    fft = wavelet(s1)\n    d5 = Concatenate(name=\"FIVE\")([SE(u4), x, fft])\n    d5 = tf.keras.layers.SeparableConv2D(32,(3,3),(1, 1),padding=\"same\")(d5)\n    d5 = tf.keras.layers.SeparableConv2D(16,(1,1),(1, 1),padding=\"same\")(d5)\n    d5 = RSU_L(d5, out_ch[10], int_ch[10], 7)\n\n    \"\"\" Side Outputs \"\"\"\n    y1 = Conv2D(num_classes, 3, padding=\"same\")(d5)\n\n    y2 = Conv2D(num_classes, 3, padding=\"same\")(d4)\n    y2 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(y2)\n\n    y3 = Conv2D(num_classes, 3, padding=\"same\")(d3)\n    y3 = UpSampling2D(size=(4, 4), interpolation=\"bilinear\")(y3)\n\n    y4 = Conv2D(num_classes, 3, padding=\"same\")(d2)\n    y4 = UpSampling2D(size=(8, 8), interpolation=\"bilinear\")(y4)\n\n    y5 = Conv2D(num_classes, 3, padding=\"same\")(d1)\n    y5 = UpSampling2D(size=(16, 16), interpolation=\"bilinear\")(y5)\n\n    y6 = Conv2D(num_classes, 3, padding=\"same\")(b1)\n    y6 = UpSampling2D(size=(32, 32), interpolation=\"bilinear\")(y6)\n\n    y1 = Activation(\"sigmoid\")(y1)\n    y2 = Activation(\"sigmoid\")(y2)\n    y3 = Activation(\"sigmoid\")(y3)\n    y4 = Activation(\"sigmoid\")(y4)\n    y5 = Activation(\"sigmoid\")(y5)\n    y6 = Activation(\"sigmoid\")(y6)\n    \n    y0 = EnsembleLayer(name=\"ensemble_layer\")([y1, y2, y3, y4, y5, y6]) \n\n    model = tf.keras.models.Model(inputs, outputs=y0)\n    return model\n\ndef build_u2net(input_shape, num_classes=1):\n    out_ch = [64, 128, 256, 512, 512, 512, 512, 256, 128, 64, 64]\n    int_ch = [32, 32, 64, 128, 256, 256, 256, 128, 64, 32, 16]\n    model = u2net(input_shape, out_ch, int_ch, num_classes=num_classes)\n    return model\n\nmodel = build_u2net((512, 512, 1))\noptimizer = Adam(lr=0.0001)\nmodel.compile(loss=combined_loss, metrics=[\"accuracy\",dice_score,recall,precision,iou], optimizer = optimizer)\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1674714143744,"user":{"displayName":"Arpita Roy","userId":"08870327934458985768"},"user_tz":-330},"id":"73b41be7","outputId":"d0f77212-ab2e-48e6-bbfc-06cb98098dd0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"88aece6c"}},{"cell_type":"code","source":"model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    filepath='/kaggle/working/seg.hdf5',\n    monitor='val_dice_score',\n    save_best_only=True,\n    save_weights_only=True,\n    mode='max',\n    verbose=1\n    )\n\nhistory = model.fit(X_train, y_train,\n                    epochs = 10,\n                    batch_size = 2,\n                    validation_data = (X_val,y_val),\n                    verbose = 1,\n                    callbacks=[model_checkpoint_callback],\n                    shuffle = True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3939889,"status":"ok","timestamp":1674718083627,"user":{"displayName":"Arpita Roy","userId":"08870327934458985768"},"user_tz":-330},"id":"3d545613","outputId":"fe28cc6c-bc69-4d36-d0b2-31125b70b4ef","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plots of metrices and losses","metadata":{}},{"cell_type":"code","source":"def Train_Val_Plot(loss, val_loss, dice_score, val_dice_score, iou, val_iou, recall, val_recall, precision, val_precision, accuracy, val_accuracy):\n    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n    fig.suptitle(\"MODEL'S METRICS VISUALIZATION\")\n\n    # Loss plot\n    axs[0, 0].plot(range(1, len(loss) + 1), loss)\n    axs[0, 0].plot(range(1, len(val_loss) + 1), val_loss)\n    axs[0, 0].set_title('History of Loss')\n    axs[0, 0].set_xlabel('Epochs')\n    axs[0, 0].set_ylabel('Loss')\n    axs[0, 0].legend(['training', 'validation'])\n\n    # Dice Coefficient plot\n    axs[0, 1].plot(range(1, len(dice_score) + 1), dice_score)\n    axs[0, 1].plot(range(1, len(val_dice_score) + 1), val_dice_score)\n    axs[0, 1].set_title('History of Dice Coefficient')\n    axs[0, 1].set_xlabel('Epochs')\n    axs[0, 1].set_ylabel('Dice Coefficient')\n    axs[0, 1].legend(['training', 'validation'])\n\n    # Mean IOU plot\n    axs[0, 2].plot(range(1, len(iou) + 1), iou)\n    axs[0, 2].plot(range(1, len(val_iou) + 1), val_iou)\n    axs[0, 2].set_title('History of IOU')\n    axs[0, 2].set_xlabel('Epochs')\n    axs[0, 2].set_ylabel('IOU')\n    axs[0, 2].legend(['training', 'validation'])\n\n    # Recall plot\n    axs[1, 0].plot(range(1, len(recall) + 1), recall)\n    axs[1, 0].plot(range(1, len(val_recall) + 1), val_recall)\n    axs[1, 0].set_title('History of Recall')\n    axs[1, 0].set_xlabel('Epochs')\n    axs[1, 0].set_ylabel('Recall')\n    axs[1, 0].legend(['training', 'validation'])\n\n    # Precision plot\n    axs[1, 1].plot(range(1, len(precision) + 1), precision)\n    axs[1, 1].plot(range(1, len(val_precision) + 1), val_precision)\n    axs[1, 1].set_title('History of Precision')\n    axs[1, 1].set_xlabel('Epochs')\n    axs[1, 1].set_ylabel('Precision')\n    axs[1, 1].legend(['training', 'validation'])\n\n    # Accuracy plot\n    axs[1, 2].plot(range(1, len(accuracy) + 1), accuracy)\n    axs[1, 2].plot(range(1, len(val_accuracy) + 1), val_accuracy)\n    axs[1, 2].set_title('History of Accuracy')\n    axs[1, 2].set_xlabel('Epochs')\n    axs[1, 2].set_ylabel('Accuracy')\n    axs[1, 2].legend(['training', 'validation'])\n\n    plt.tight_layout()\n    plt.show()\n\nTrain_Val_Plot(\n    history.history['loss'], history.history['val_loss'],\n    history.history['dice_score'], history.history['val_dice_score'],\n    history.history['iou'], history.history['val_iou'],\n    history.history['recall'], history.history['val_recall'],\n    history.history['precision'], history.history['val_precision'],\n    history.history['accuracy'], history.history['val_accuracy']\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"elapsed":2389,"status":"ok","timestamp":1674718086000,"user":{"displayName":"Arpita Roy","userId":"08870327934458985768"},"user_tz":-330},"id":"5afb4e42","outputId":"540bd7ed-eab4-4251-9716-61b5368292c5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{"id":"1fa81e10"}},{"cell_type":"markdown","source":"#### Testing results","metadata":{}},{"cell_type":"code","source":"model.load_weights(\"/kaggle/working/seg.hdf5\")\nmodel.evaluate(X_test, y_test, batch_size=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Segmentation output","metadata":{}},{"cell_type":"markdown","source":"##### Decoders","metadata":{}},{"cell_type":"code","source":"modeller = tf.keras.models.Model(inputs=model.input, outputs=[model.get_layer(name=\"up_sampling2d_33\").output,model.get_layer(name=\"up_sampling2d_34\").output,model.get_layer(name=\"up_sampling2d_35\").output,model.get_layer(name=\"up_sampling2d_36\").output,model.get_layer(name=\"up_sampling2d_37\").output])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for w in range(40):\n    # Load one image and corresponding mask from the test dataset\n    test_image = X_test[w]  # Replace X_test with your actual test dataset\n    test_mask = y_test[w]  # Replace y_test with your actual test masks\n\n    # Reshape the image to match the input shape of the model\n    test_image = np.reshape(test_image, (1,) + test_image.shape)\n\n    # Predict the segmentation mask for the test image\n    predicted_mask = model.predict(test_image)[0]\n    feature_map1, feature_map2, feature_map3, feature_map4, feature_map5 = modeller.predict(test_image)\n\n    # Convert the predicted mask values to binary (0 or 1)\n    predicted_mask_binary = np.where(predicted_mask > 0.5, 1, 0) * 255\n\n    # Create subplots\n    fig, axes = plt.subplots(1, 8, figsize=(20, 4))  # Adjusted the number of subplots\n\n    # Plot the test image\n    axes[0].imshow(test_image[0], cmap='gray')\n    axes[0].set_title('Test Image')\n    axes[0].axis('off')\n\n    # Plot the ground truth mask\n    axes[1].imshow(test_mask, cmap='gray')\n    axes[1].set_title('Ground Truth Mask')\n    axes[1].axis('off')\n\n    # Plot the predicted mask\n    axes[2].imshow(predicted_mask_binary, cmap='gray')\n    axes[2].set_title('Predicted Mask')\n    axes[2].axis('off')\n\n    # Plot the feature maps (Set 1)\n    for i in range(5):\n        axes[i + 3].imshow(eval(f'feature_map{i + 1}')[0, :, :, 0], cmap='jet')\n        axes[i + 3].set_title(f'Feature Map {i + 1} (Set 1)')\n        axes[i + 3].axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}